== Example Flow 1
In this first example, the Compute and Transfer **flow** takes a `globus-transfer-transfer#0.10` object from a transfer and determines the source files and desitnation endpoint from

The **flow** creates a tarfile from those files and transfers the tarfile to a user-provided destination collection. This **flow** will fail if any source paths are the path '/' or contain the character '~'.

The **flow** is intended to be invoked from the Globus webapp when initating a transfer where the **source** collection has this flow set as the source in its `associated_flow_policy`.

The **flow** will:

1. Set constants for the **run**
2. Validate the input source paths
3. Create an output directory named after the **run**'s ID on the source collection
4. Invoke the `do_tar` **function** to create a tar archive from the input source files and save it in the output directory
5. Transfer the resulting tarfile to the destination collection provided in the **flow** input
6. Delete the output directory on the source collection

=== Create the **Flow**

1. Edit `compute_transfer_example_1_definition.json` and replace the placeholder values:

   - `compute_endpoint_id`: The Compute **endpoint** ID
   - `compute_function_id`: The UUID of the registered `do_tar` **function**

If the **collection** has a configured base path, also edit `gcs_base_path`.

2. Create the **flow**:
+
[source,bash,role=clippable-code]
----
globus flows create "Compute and Transfer Flow Example 1" \
   ./compute_transfer_example_1_definition.json \
   --input-schema ./compute_transfer_example_1_schema.json
----

3. Save the **flow** ID returned by this command

ifndef::env-github[]
[.accordionize]
--
.compute_transfer_example_1_definition.json
[%collapsible]
====
[source,json,role=clippable-code]
----
include::compute_transfer_example_1_definition.json[]
----
====
.compute_transfer_example_1_schema.json
[%collapsible]
====
[source,json,role=clippable-code]
----
include::compute_transfer_example_1_schema.json[]
----
====
--
endif::[]

=== Run the **Flow**

1. Create the **flow** input JSON file:
+
[source,json,role=clippable-code]
----
{
    "destination_path": "/path/to/your/destination/file.tar.gz",
}
----

[NOTE]
======
`destination_path` is an optional property. If left unset, the flow will try to save the output tarball to `/~/<random UUID>.tar.gz`.
======

2. Start the **flow**:
+
[source,bash,role=clippable-code]
----
globus flows start "$FLOW_ID" \
   --input "<FLOW INPUT FILE>" \
   --label "Compute and Transfer Flow Example 1 Run"
----
+
And save the **run** ID for use in the next command.

3. Monitor the **run** progress:
+
[source,bash,role=clippable-code]
----
globus flows run show "<RUN_ID>"
----
** At this point, the **run** _may_ become `INACTIVE`, depending on the type of **collection** being used.
** For inactive **run**s due to data access requirements, this can be resolved by resuming the **run** and following the prompts:
+
[source,bash,role=clippable-code]
----
globus flows run resume "<RUN_ID>"
----
+
When prompted, run `globus session consent` and rerun `globus flows run resume` to resume the **run**.

ifdef::env-github[]
== Next: Example Flow 2, with Data on a Separate **Collection**

link:./example_flow2.adoc[Example Flow 2.]
endif::[]